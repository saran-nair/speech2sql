# Speech2SQL: Voice-Powered SQL Generation with RAG & GenAI


## üîç Project Overview

**Speech2SQL** is an end-to-end, voice-driven SQL query generation app. It uses a fine-tuned Whisper model for ASR (Automatic Speech Recognition), Retrieval-Augmented Generation (RAG) for schema understanding, and a local LLM (e.g., Phi-2, TinyLlama, Falcon) to generate executable SQL queries. All components are self-contained and run offline, making it ideal for secure environments.

---

## üéØ Key Features

* **üéôÔ∏è Speech Input**: Upload voice/audio files in `.wav` or `.mp3`
* **üß† ASR via Fine-Tuned Whisper**: Customized for Indian and Scottish accents
* **üìö RAG-based Schema Retrieval**: Uses ChromaDB to fetch relevant schema context
* **üßæ SQL Generation**: Uses local LLM (Phi-2, Falcon, or TinyLlama) for query formulation
* **üîÅ Query Execution**: Run SQL on mock SQLite databases
* **üñ•Ô∏è Streamlit UI**: Simple, interactive, browser-based front-end
* **‚ö° Fully Offline**: All models run locally (ideal for air-gapped/GPU servers)

---

## üß± System Architecture

![Architecture Diagram](docs/architecture.png)

---

## ‚öôÔ∏è Tech Stack

* **ASR**: [Whisper](https://github.com/openai/whisper), fine-tuned with Hugging Face Transformers
* **LLM**: [Phi-2](https://huggingface.co/microsoft/phi-2) or [TinyLlama](https://huggingface.co/NousResearch/TinyLlama-1.1B-Chat-v1.0)
* **Retriever**: [ChromaDB](https://docs.trychroma.com/) + Sentence Transformers
* **Frontend**: [Streamlit](https://streamlit.io/)
* **Database**: SQLite (mock schema)

---

## üöÄ Getting Started

### 1. Clone the Repo

```bash
git clone https://github.com/saran-nair/speech2sql.git
cd speech2sql
```

### 2. Install Dependencies

```bash
pip install -r requirements2.txt
```

### 3. Index Schema into Chroma

```bash
python app/rag/schema_indexer.py  # indexes mock_schema.sql
```

### 4. Launch the App

```bash
streamlit run app/ui/streamlit_app.py
```

Then open [http://localhost:8501](http://localhost:8501) in your browser.

> üí° Use SSH tunneling if running on a remote GPU (e.g., on premise/private cluster):
> `ssh -L 8501:localhost:8501 your@remote.host`

---

## üìÇ Project Structure

```
speech-to-sql-genai/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ asr/                  # Whisper inference + audio utilities
‚îÇ   ‚îú‚îÄ‚îÄ rag/                  # RAG logic (ChromaDB + indexer)
‚îÇ   ‚îú‚îÄ‚îÄ llm/                  # Local LLM wrapper (SQL generation)
‚îÇ   ‚îú‚îÄ‚îÄ ui/                   # Streamlit frontend
‚îÇ   ‚îú‚îÄ‚îÄ db/                   # SQLite DB + schema files + Chroma store
‚îú‚îÄ‚îÄ Fine_Tuned_Model/         # Fine-tuned Whisper model
‚îú‚îÄ‚îÄ requirements2.txt
‚îú‚îÄ‚îÄ README.md
```

---

## üìå Sample Schema Used

```sql
CREATE TABLE customers (
  id INTEGER PRIMARY KEY,
  name TEXT,
  country TEXT
);

CREATE TABLE orders (
  id INTEGER PRIMARY KEY,
  customer_id INTEGER,
  order_date DATE,
  total_amount FLOAT
);
```

---

## ‚ú® Example Use Case

**Voice Input**:

> "What is the total amount of orders placed by customers from Germany?"

**Generated SQL**:

```sql
SELECT SUM(total_amount) FROM orders
WHERE customer_id IN (
  SELECT id FROM customers WHERE country = 'Germany'
);
```

**Result**:

```
(350.5,)
```

---

## üõ£Ô∏è Roadmap

* [ ] Add support for multiple schemas (e.g., `employee_db`, `finance_db`)
* [ ] Enable microphone-based input (live voice recording)

---

![Screenshot](docs/screenshot.png)

## üß† Acknowledgements

* OpenAI Whisper for ASR
* Microsoft Phi-2 / TinyLlama for LLMs
* ChromaDB for simple RAG
* Hugging Face Transformers
* Streamlit for the UI

---

## üìú License

[MIT](LICENSE)